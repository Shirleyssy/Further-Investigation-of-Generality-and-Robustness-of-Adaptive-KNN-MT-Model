{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29ac53e-c629-4efd-bb24-17ed2e844e24",
   "metadata": {},
   "source": [
    "# Install All dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52ee94-639e-4fe4-9b92-605829db76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcb762-a79b-4887-9bb7-dc9d8409c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/zhengxxn/adaptive-knn-mt.git\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572495a7-4031-41dd-b367-719e6e216de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch-scatter -f https://data.pyg.org/whl/torch-1.9.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18e422-6f6e-4fc1-b428-64dc2010f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sacremoses\n",
    "! pip install sacrebleu==1.4.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e105058-e060-4af3-a92b-c0f48b788614",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e adaptive-knn-mt/\n",
    "! pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb047b7-a8b7-4e60-b472-2654953d07db",
   "metadata": {},
   "source": [
    "# Generate Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb1978-6d1a-4eb5-abcf-534d6a374772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it\n",
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "%env DATA_PATH=it\n",
    "%env DATASTORE_PATH=it_data_store\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/save_datastore.py $DATA_PATH \\\n",
    "    --dataset-impl mmap \\\n",
    "    --task translation \\\n",
    "    --valid-subset train \\\n",
    "    --path $MODEL_PATH \\\n",
    "    --max-tokens 4096 --skip-invalid-size-inputs-valid-test \\\n",
    "    --decoder-embed-dim 1024 --dstore-fp16 --dstore-size $DSTORE_SIZE --dstore-mmap $DATASTORE_PATH\n",
    " \n",
    "# 4096 and 1024 depend on your device and model separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c614d19-5c74-482d-b6a0-94468fca48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical\n",
    "%env DSTORE_SIZE=6903320\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "%env DATA_PATH=medical\n",
    "%env DATASTORE_PATH=medical_data_store\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/save_datastore.py $DATA_PATH \\\n",
    "    --dataset-impl mmap \\\n",
    "    --task translation \\\n",
    "    --valid-subset train \\\n",
    "    --path $MODEL_PATH \\\n",
    "    --max-tokens 4096 --skip-invalid-size-inputs-valid-test \\\n",
    "    --decoder-embed-dim 1024 --dstore-fp16 --dstore-size $DSTORE_SIZE --dstore-mmap $DATASTORE_PATH\n",
    " \n",
    "# 4096 and 1024 depend on your device and model separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe636ef2-e177-464a-9088-137b2b32d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koran\n",
    "%env DSTORE_SIZE=524400\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "%env DATA_PATH=koran\n",
    "%env DATASTORE_PATH=koran_data_store\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/save_datastore.py $DATA_PATH \\\n",
    "    --dataset-impl mmap \\\n",
    "    --task translation \\\n",
    "    --valid-subset train \\\n",
    "    --path $MODEL_PATH \\\n",
    "    --max-tokens 4096 --skip-invalid-size-inputs-valid-test \\\n",
    "    --decoder-embed-dim 1024 --dstore-fp16 --dstore-size $DSTORE_SIZE --dstore-mmap $DATASTORE_PATH\n",
    " \n",
    "# 4096 and 1024 depend on your device and model separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b89cdb-efb7-4934-958c-a23a8dc42685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# law\n",
    "%env DSTORE_SIZE=19070000\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "%env DATA_PATH=law\n",
    "%env DATASTORE_PATH=law_data_store\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/save_datastore.py $DATA_PATH \\\n",
    "    --dataset-impl mmap \\\n",
    "    --task translation \\\n",
    "    --valid-subset train \\\n",
    "    --path $MODEL_PATH \\\n",
    "    --max-tokens 4096 --skip-invalid-size-inputs-valid-test \\\n",
    "    --decoder-embed-dim 1024 --dstore-fp16 --dstore-size $DSTORE_SIZE --dstore-mmap $DATASTORE_PATH\n",
    " \n",
    "# 4096 and 1024 depend on your device and model separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c844e-4143-42ca-995a-9a57b2e1cd7c",
   "metadata": {},
   "source": [
    "# Genreate Faiss Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afc6c5-12ff-48cb-8685-4b63ecc35c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "%env DSTORE_PATH=it_data_store\n",
    "%env DSTORE_SIZE=3613350\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/train_datastore_gpu.py \\\n",
    "    --dstore_mmap $DSTORE_PATH \\\n",
    "    --dstore_size $DSTORE_SIZE \\\n",
    "    --dstore-fp16 \\\n",
    "    --faiss_index ${DSTORE_PATH}/knn_index \\\n",
    "    --ncentroids 4096 \\\n",
    "    --probe 32 \\\n",
    "    --dimension 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6d947-38b2-4ee0-8230-237e74d35373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "%env DSTORE_PATH=medical_data_store\n",
    "%env DSTORE_SIZE=6903320\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/train_datastore_gpu.py \\\n",
    "    --dstore_mmap $DSTORE_PATH \\\n",
    "    --dstore_size $DSTORE_SIZE \\\n",
    "    --dstore-fp16 \\\n",
    "    --faiss_index ${DSTORE_PATH}/knn_index \\\n",
    "    --ncentroids 4096 \\\n",
    "    --probe 32 \\\n",
    "    --dimension 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52c228-e8e6-42f6-8e6d-5ce9ba69d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# koran\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "%env DSTORE_PATH=koran_data_store\n",
    "%env DSTORE_SIZE=524400\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/train_datastore_gpu.py \\\n",
    "    --dstore_mmap $DSTORE_PATH \\\n",
    "    --dstore_size $DSTORE_SIZE \\\n",
    "    --dstore-fp16 \\\n",
    "    --faiss_index ${DSTORE_PATH}/knn_index \\\n",
    "    --ncentroids 4096 \\\n",
    "    --probe 32 \\\n",
    "    --dimension 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25722-4798-4207-95a3-0e2bdf94a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# law\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "%env DSTORE_PATH=law_data_store\n",
    "%env DSTORE_SIZE=19070000\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/train_datastore_gpu.py \\\n",
    "    --dstore_mmap $DSTORE_PATH \\\n",
    "    --dstore_size $DSTORE_SIZE \\\n",
    "    --dstore-fp16 \\\n",
    "    --faiss_index ${DSTORE_PATH}/knn_index \\\n",
    "    --ncentroids 4096 \\\n",
    "    --probe 32 \\\n",
    "    --dimension 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3166a5-d6dd-4d0e-acfb-6de6a3272568",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a3d28-2700-48ee-b0d3-245be250b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the training script according to the description in the README\n",
    "! bash train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa468145-292b-4f58-99c8-926f6433570a",
   "metadata": {},
   "source": [
    "# Inference for IT domain\n",
    "This is just part of our code. The code for inference for each domain is pretty similar. We just reused our code by changing the parameters as the way we stated in the README file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d22ca-f17c-43c4-95d0-e2a6a6a435bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=model_record/train-hid32-maxk1/checkpoint.best_loss_1.97.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "! mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH \\\n",
    "--gen-subset test --path $MODEL_PATH \\\n",
    "--arch transformer_wmt19_de_en_with_datastore \\\n",
    "--beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en \\\n",
    "--scoring sacrebleu \\\n",
    "--batch-size 32 \\\n",
    "--tokenizer moses --remove-bpe \\\n",
    "--model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True, \\\n",
    "'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, \\\n",
    "'dstore_fp16': True, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', \\\n",
    "'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True, \\\n",
    "'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "| tee \"$OUTPUT_PATH\"/generate.txt\n",
    "\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3c17b-f3c5-41a7-8071-cf72b00daaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=model_record/train-hid32-maxk2/checkpoint.best_loss_1.88.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "! mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH \\\n",
    "--gen-subset test --path $MODEL_PATH \\\n",
    "--arch transformer_wmt19_de_en_with_datastore \\\n",
    "--beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en \\\n",
    "--scoring sacrebleu \\\n",
    "--batch-size 32 \\\n",
    "--tokenizer moses --remove-bpe \\\n",
    "--model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True, \\\n",
    "'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, \\\n",
    "'dstore_fp16': True, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', \\\n",
    "'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True, \\\n",
    "'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "| tee \"$OUTPUT_PATH\"/generate.txt\n",
    "\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1192ba-4ffd-4947-8832-712098252d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=model_record/train-hid32-maxk4/checkpoint.best_loss_1.83.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "! mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "! CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH \\\n",
    "--gen-subset test --path $MODEL_PATH \\\n",
    "--arch transformer_wmt19_de_en_with_datastore \\\n",
    "--beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en \\\n",
    "--scoring sacrebleu \\\n",
    "--batch-size 32 \\\n",
    "--tokenizer moses --remove-bpe \\\n",
    "--model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True, \\\n",
    "'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, \\\n",
    "'dstore_fp16': True, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', \\\n",
    "'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True, \\\n",
    "'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "| tee \"$OUTPUT_PATH\"/generate.txt\n",
    "\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5e451-83f3-4150-a300-333c0e8dd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "%env DATA_PATH=it\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "!mkdir -p $OUTPUT_PATH\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/fairseq_cli/generate.py $DATA_PATH\\\n",
    "    --gen-subset test \\\n",
    "    --path $MODEL_PATH \\\n",
    "    --beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en \\\n",
    "    --scoring sacrebleu \\\n",
    "    --max-tokens 4096 \\\n",
    "    --tokenizer moses --remove-bpe | tee $OUTPUT_PATH/generate.txt\n",
    "\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffaba3-7bab-4516-9803-9d35d235377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla\n",
    "\n",
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "!mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH\\\n",
    "    --gen-subset test\\\n",
    "    --path $MODEL_PATH --arch transformer_wmt19_de_en_with_datastore\\\n",
    "    --beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en\\\n",
    "    --scoring sacrebleu\\\n",
    "    --batch-size 32\\\n",
    "    --tokenizer moses --remove-bpe\\\n",
    "    --model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True,'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, 'dstore_fp16': True, 'k': 1, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', 'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True,'knn_lambda_type': 'fix', 'knn_lambda_value': 0.7, 'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "    | tee \"$OUTPUT_PATH\"/generate.txt\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3bc59f-779e-40fd-929f-dfa9a981b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "!mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH\\\n",
    "    --gen-subset test\\\n",
    "    --path $MODEL_PATH --arch transformer_wmt19_de_en_with_datastore\\\n",
    "    --beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en\\\n",
    "    --scoring sacrebleu\\\n",
    "    --batch-size 32\\\n",
    "    --tokenizer moses --remove-bpe\\\n",
    "    --model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True,'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, 'dstore_fp16': True, 'k': 2, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', 'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True,'knn_lambda_type': 'fix', 'knn_lambda_value': 0.7, 'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "    | tee \"$OUTPUT_PATH\"/generate.txt\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9d09a-2515-4abf-b75c-dfcbd2e45085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DSTORE_SIZE=3613350\n",
    "%env MODEL_PATH=Model/wmt19.de-en.ffn8192.pt\n",
    "\n",
    "%env DATASTORE_PATH=data_store\n",
    "%env DATA_PATH=it\n",
    "%env PROJECT_PATH=adaptive-knn-mt\n",
    "\n",
    "%env OUTPUT_PATH=output\n",
    "\n",
    "!mkdir -p \"$OUTPUT_PATH\"\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python $PROJECT_PATH/experimental_generate.py $DATA_PATH\\\n",
    "    --gen-subset test\\\n",
    "    --path $MODEL_PATH --arch transformer_wmt19_de_en_with_datastore\\\n",
    "    --beam 4 --lenpen 0.6 --max-len-a 1.2 --max-len-b 10 --source-lang de --target-lang en\\\n",
    "    --scoring sacrebleu\\\n",
    "    --batch-size 32\\\n",
    "    --tokenizer moses --remove-bpe\\\n",
    "    --model-overrides \"{'load_knn_datastore': True, 'use_knn_datastore': True,'dstore_filename': '$DATASTORE_PATH', 'dstore_size': $DSTORE_SIZE, 'dstore_fp16': True, 'k': 4, 'probe': 32,'knn_sim_func': 'do_not_recomp_l2', 'use_gpu_to_search': True, 'move_dstore_to_mem': True, 'no_load_keys': True,'knn_lambda_type': 'fix', 'knn_lambda_value': 0.7, 'knn_temperature_type': 'fix', 'knn_temperature_value': 10,}\" \\\n",
    "    | tee \"$OUTPUT_PATH\"/generate.txt\n",
    "!grep ^S \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/src\n",
    "!grep ^T \"$OUTPUT_PATH\"/generate.txt | cut -f2- > \"$OUTPUT_PATH\"/ref\n",
    "!grep ^H \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp\n",
    "!grep ^D \"$OUTPUT_PATH\"/generate.txt | cut -f3- > \"$OUTPUT_PATH\"/hyp.detok"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
